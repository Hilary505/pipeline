{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f1c75cea-b28b-486b-8575-bcb1f2faa7f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Imputer statistics_: [ 4. 13.  6.]\n",
      "\n",
      "Transformed train_data:\n",
      " [[ 7.  6.  5.]\n",
      " [ 4. 13.  5.]\n",
      " [ 1. 20.  8.]]\n",
      "\n",
      "Transformed test_data:\n",
      " [[ 4.  1.  2.]\n",
      " [ 7. 13.  9.]\n",
      " [ 4.  2.  4.]]\n"
     ]
    }
   ],
   "source": [
    "#Exercise 1: Imputer 1\n",
    "import numpy as np\n",
    "from sklearn.impute import SimpleImputer \n",
    "\n",
    "# Training data with missing values\n",
    "train_data = [[7, 6, 5],\n",
    "              [4, np.nan, 5],\n",
    "              [1, 20, 8]]\n",
    "\n",
    "# Create SimpleImputer (default strategy = \"mean\")\n",
    "imputer = SimpleImputer(strategy=\"mean\")\n",
    "\n",
    "# Fit the imputer on the training data\n",
    "imputer.fit(train_data)\n",
    "\n",
    "# Print statistics_ (mean of each column)\n",
    "print(\"Imputer statistics_:\",imputer.statistics_)\n",
    "\n",
    "\n",
    "# Transform train_data (fill missing values)\n",
    "train_filled = imputer.transform(train_data)\n",
    "print(\"\\nTransformed train_data:\\n\", train_filled)\n",
    "\n",
    "# Test data\n",
    "test_data = [[np.nan, 1, 2],\n",
    "             [7, np.nan, 9],\n",
    "             [np.nan, 2, 4]]\n",
    "\n",
    "# Transform test_data using the same imputer (trained on train_data)\n",
    "test_filled = imputer.transform(test_data)\n",
    "print(\"\\nTransformed test_data:\\n\", test_filled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "90f61687-7a32-4bb4-9110-486ebe9eb91a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_train:\n",
      " array([[ 0.        , -1.22474487,  1.33630621],\n",
      "       [ 1.22474487,  0.        , -0.26726124],\n",
      "       [-1.22474487,  1.22474487, -1.06904497]])\n",
      "\n",
      "Scaled X_test:\n",
      " array([[ 1.22474487, -1.22474487,  0.53452248],\n",
      "       [ 2.44948974,  3.67423461, -1.06904497],\n",
      "       [ 0.        ,  1.22474487,  0.53452248]])\n"
     ]
    }
   ],
   "source": [
    "# Exercise 2: Scaler\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Training data\n",
    "X_train = np.array([[ 1., -1.,  2.],\n",
    "                    [ 2.,  0.,  0.],\n",
    "                    [ 0.,  1., -1.]])\n",
    "\n",
    "# Create scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit on training data and transform\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "print(\"\\nX_train:\\n\", repr(X_train_scaled))\n",
    "\n",
    "# Test data\n",
    "X_test = np.array([[ 2., -1.,  1.],\n",
    "                   [ 3.,  3., -1.],\n",
    "                   [ 1.,  1.,  1.]])\n",
    "\n",
    "# Transform test data (using the same scaler)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "print(\"\\nScaled X_test:\\n\", repr(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c88742f-f8d3-4d4b-98a9-c31b7ee7e38f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train one-hot encoded:\n",
      "    C++  Java  Python\n",
      "0    0     0       1\n",
      "1    0     1       0\n",
      "2    0     1       0\n",
      "3    1     0       0\n",
      "\n",
      "Test one-hot encoded:\n",
      "    C++  Java  Python\n",
      "0    0     0       1\n",
      "1    0     1       0\n",
      "2    0     0       0\n",
      "3    1     0       0\n"
     ]
    }
   ],
   "source": [
    "# Exercise 3: One hot Encoder\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Training data\n",
    "X_train = [['Python'], ['Java'], ['Java'], ['C++']]\n",
    "\n",
    "# Create encoder\n",
    "encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "\n",
    "# Fit and transform on training data\n",
    "X_train_encoded = encoder.fit_transform(X_train).toarray()\n",
    "\n",
    "# Get categories (each element is a tuple)\n",
    "categories = encoder.categories_[0]\n",
    "\n",
    "# Create DataFrame with categories as column names\n",
    "df_train = pd.DataFrame(X_train_encoded.astype(int), columns=categories)\n",
    "\n",
    "print(\"Train one-hot encoded:\\n\", df_train)\n",
    "\n",
    "# Test data\n",
    "X_test = [['Python'], ['Java'], ['C'], ['C++']]\n",
    "\n",
    "# Transform test data\n",
    "X_test_encoded = encoder.transform(X_test).toarray()\n",
    "\n",
    "df_test = pd.DataFrame(X_test_encoded.astype(int), columns=categories)\n",
    "\n",
    "print(\"\\nTest one-hot encoded:\\n\", df_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fc69d230-f0d6-44c9-9520-1a15791437b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transformed X_train:\n",
      " array([[2.],\n",
      "       [0.],\n",
      "       [1.]])\n",
      "\n",
      "Categories: [array(['bad', 'neutral', 'good'], dtype=object)]\n",
      "\n",
      "Transformed X_test:\n",
      " array([[2.],\n",
      "       [2.],\n",
      "       [0.]])\n"
     ]
    }
   ],
   "source": [
    "# Exercise 4: Ordinal Encoder\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Training data\n",
    "X_train = [['good'], ['bad'], ['neutral']]\n",
    "\n",
    "# Define the category order\n",
    "encoder = OrdinalEncoder(categories=[['bad', 'neutral', 'good']])\n",
    "\n",
    "# Fit and transform the training data\n",
    "X_train_encoded = encoder.fit_transform(X_train)\n",
    "\n",
    "print(\"Transformed X_train:\\n\", repr(X_train_encoded))\n",
    "\n",
    "# Print the categories_\n",
    "print(\"\\nCategories:\", encoder.categories_)\n",
    "\n",
    "# Test data\n",
    "X_test = [['good'], ['good'], ['bad']]\n",
    "\n",
    "# Transform test data using the fitted encoder\n",
    "X_test_encoded = encoder.transform(X_test)\n",
    "print(\"\\nTransformed X_test:\\n\", repr(X_test_encoded))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "48df2f11-f42f-4e9c-89bc-52699e95d499",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age             6\n",
      "menopause       3\n",
      "tumor-size     11\n",
      "inv-nodes       6\n",
      "node-caps       2\n",
      "deg-malig       3\n",
      "breast          2\n",
      "breast-quad     5\n",
      "irradiat        2\n",
      "dtype: int64\n",
      "\n",
      "# Question 2 - First 10 rows of OHE transform on test set\n",
      "array([[1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.],\n",
      "       [1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.],\n",
      "       [0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1.],\n",
      "       [0., 1., 1., 0., 0., 1., 0., 0., 0., 0., 1.],\n",
      "       [1., 0., 1., 0., 0., 0., 1., 0., 0., 1., 0.],\n",
      "       [1., 0., 1., 0., 0., 0., 0., 1., 0., 1., 0.],\n",
      "       [1., 0., 0., 1., 0., 0., 0., 0., 1., 1., 0.],\n",
      "       [1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0.],\n",
      "       [1., 0., 1., 0., 0., 0., 0., 1., 0., 0., 1.],\n",
      "       [1., 0., 0., 1., 0., 1., 0., 0., 0., 1., 0.]])\n",
      "\n",
      "# OHE feature names\n",
      "['node-caps_no' 'node-caps_yes' 'breast_left' 'breast_right'\n",
      " 'breast-quad_central' 'breast-quad_left_low' 'breast-quad_left_up'\n",
      " 'breast-quad_right_low' 'breast-quad_right_up' 'irradiat_no'\n",
      " 'irradiat_yes']\n",
      "\n",
      "# First 10 rows of OrdinalEncoder transform on test set\n",
      "array([[2., 5., 2., 0., 1.],\n",
      "       [2., 5., 2., 0., 0.],\n",
      "       [2., 5., 4., 5., 2.],\n",
      "       [1., 4., 5., 1., 1.],\n",
      "       [2., 5., 5., 0., 2.],\n",
      "       [1., 2., 1., 0., 1.],\n",
      "       [1., 2., 8., 0., 1.],\n",
      "       [2., 5., 2., 0., 0.],\n",
      "       [2., 5., 5., 0., 2.],\n",
      "       [1., 2., 3., 0., 0.]])\n",
      "\n",
      "# First 2 rows of ColumnTransformer applied to test set\n",
      "array([[2., 5., 2., 0., 1., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.],\n",
      "       [2., 5., 2., 0., 0., 1., 0., 1., 0., 0., 1., 0., 0., 0., 1., 0.]])\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import make_column_transformer\n",
    "\n",
    "# 1. Load dataset\n",
    "df = pd.read_csv(\"breast-cancer.csv\", header=None)\n",
    "\n",
    "df.columns = [\n",
    "    \"age\", \"menopause\", \"tumor-size\", \"inv-nodes\", \"node-caps\",\n",
    "    \"deg-malig\", \"breast\", \"breast-quad\", \"irradiat\", \"Class\"\n",
    "]\n",
    "\n",
    "# Drop NaN if present\n",
    "df = df.dropna()\n",
    "\n",
    "# 2. Train-test split\n",
    "X = df.drop(\"Class\", axis=1)\n",
    "y = df[\"Class\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=43\n",
    ")\n",
    "\n",
    "# 3. Question 1: Unique values\n",
    "print(X_train.nunique())\n",
    "\n",
    "# 4. Question 2: OneHotEncoder on nominal features\n",
    "ohe_cols = [\"node-caps\", \"breast\", \"breast-quad\", \"irradiat\"]\n",
    "ohe = OneHotEncoder(sparse_output=False, handle_unknown=\"ignore\")\n",
    "ohe.fit(X_train[ohe_cols])\n",
    "\n",
    "print(\"\\n# Question 2 - First 10 rows of OHE transform on test set\")\n",
    "print(repr(ohe.transform(X_test[ohe_cols])[:10]))\n",
    "\n",
    "print(\"\\n# OHE feature names\")\n",
    "print(ohe.get_feature_names_out(ohe_cols))\n",
    "\n",
    "# 5. Question 3: OrdinalEncoder on ordinal features\n",
    "ordinal_cols = [\"menopause\", \"age\", \"tumor-size\", \"inv-nodes\", \"deg-malig\"]\n",
    "\n",
    "ordinal_categories = [\n",
    "    [\"lt40\", \"premeno\", \"ge40\"],  # menopause\n",
    "    [\"10-19\", \"20-29\", \"30-39\", \"40-49\", \"50-59\", \"60-69\", \"70-79\", \"80-89\", \"90-99\"],  # age\n",
    "    [\"0-4\",\"5-9\",\"10-14\",\"15-19\",\"20-24\",\"25-29\",\"30-34\",\"35-39\",\"40-44\",\n",
    "     \"45-49\",\"50-54\",\"55-59\"],  # tumor-size\n",
    "    [\"0-2\",\"3-5\",\"6-8\",\"9-11\",\"12-14\",\"15-17\",\"18-20\",\"21-23\",\"24-26\",\n",
    "     \"27-29\",\"30-32\",\"33-35\",\"36-39\"],  # inv-nodes\n",
    "    [1, 2, 3]  # deg-malig\n",
    "]\n",
    "\n",
    "oe = OrdinalEncoder(categories=ordinal_categories)\n",
    "oe.fit(X_train[ordinal_cols])\n",
    "\n",
    "print(\"\\n# First 10 rows of OrdinalEncoder transform on test set\")\n",
    "print(repr(oe.transform(X_test[ordinal_cols])[:10]))\n",
    "\n",
    "# 6. Question 4: Combine with ColumnTransformer\n",
    "preprocessor = make_column_transformer(\n",
    "    (oe, ordinal_cols),\n",
    "    (ohe, ohe_cols),\n",
    "    remainder=\"drop\"\n",
    ")\n",
    "\n",
    "preprocessor.fit(X_train)\n",
    "\n",
    "print(\"\\n# First 2 rows of ColumnTransformer applied to test set\")\n",
    "print(repr(preprocessor.transform(X_test)[:2]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f23c5f34-02ce-4db0-ade8-022e5f69d04a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model score on test set: 98%\n"
     ]
    }
   ],
   "source": [
    "#Exercise 6: Pipeline\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n",
    "# Load iris dataset\n",
    "iris = load_iris()\n",
    "X, y = iris['data'], iris['target']\n",
    "\n",
    "# Add missing values\n",
    "X[[1, 20, 50, 100, 135], 0] = np.nan\n",
    "X[[2, 5, 88, 135], 1] = np.nan\n",
    "X[[4, 15], 2] = np.nan\n",
    "X[[40, 135], 3] = np.nan\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.33, random_state=43\n",
    ")\n",
    "\n",
    "# Define pipeline\n",
    "pipeline = Pipeline([\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"logreg\", LogisticRegression(max_iter=1000, random_state=43))\n",
    "])\n",
    "\n",
    "# Fit pipeline\n",
    "pipeline.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate on test set\n",
    "score = pipeline.score(X_test, y_test)\n",
    "\n",
    "print(f\"Model score on test set: {int(score * 100)}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "118d13a6-9460-45d3-8b1d-e0c89c3aa9d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
